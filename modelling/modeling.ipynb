{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.utils import all_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set this to the root directory of the project\n",
    "path_root_dir=\"C:/Users/Ramesh Babu/BuzzOnEarth/datasets/\"\n",
    "data = pd.read_csv(path_root_dir + \"processed/all_city_data_with_pop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>geometry</th>\n",
       "      <th>parking</th>\n",
       "      <th>edges</th>\n",
       "      <th>EV_stations</th>\n",
       "      <th>parking_space</th>\n",
       "      <th>civic</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>park</th>\n",
       "      <th>...</th>\n",
       "      <th>cinema</th>\n",
       "      <th>library</th>\n",
       "      <th>commercial</th>\n",
       "      <th>retail</th>\n",
       "      <th>townhall</th>\n",
       "      <th>government</th>\n",
       "      <th>residential</th>\n",
       "      <th>city</th>\n",
       "      <th>population</th>\n",
       "      <th>Berlin_data_onlycenter_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((8.4727605 50.099822499999995, 8.4730...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>9.014051</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((8.4775730092433 50.10302720327834, 8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((8.479750879173663 50.09863320231676,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>9.014051</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((8.479688060978736 50.10443297769501,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>9.014051</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((8.47965547981383 50.107440331063444,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0   \n",
       "0             0           0  \\\n",
       "1             1           1   \n",
       "2             2           2   \n",
       "3             3           3   \n",
       "4             4           4   \n",
       "\n",
       "                                            geometry  parking  edges   \n",
       "0  POLYGON ((8.4727605 50.099822499999995, 8.4730...        0      0  \\\n",
       "1  POLYGON ((8.4775730092433 50.10302720327834, 8...        0      0   \n",
       "2  POLYGON ((8.479750879173663 50.09863320231676,...        0      0   \n",
       "3  POLYGON ((8.479688060978736 50.10443297769501,...        0      0   \n",
       "4  POLYGON ((8.47965547981383 50.107440331063444,...        0      0   \n",
       "\n",
       "   EV_stations  parking_space  civic  restaurant  park  ...  cinema  library   \n",
       "0            0              0      0           0     0  ...       0        0  \\\n",
       "1            0              0      0           0     0  ...       0        0   \n",
       "2            0              0      0           0     0  ...       0        0   \n",
       "3            0              0      0           0     0  ...       0        0   \n",
       "4            0              0      0           0     0  ...       0        0   \n",
       "\n",
       "   commercial  retail  townhall  government  residential       city   \n",
       "0           0       0         0         0.0            0  Frankfurt  \\\n",
       "1           0       0         0         0.0            0  Frankfurt   \n",
       "2           0       0         0         0.0            0  Frankfurt   \n",
       "3           0       0         0         0.0            0  Frankfurt   \n",
       "4           0       0         0         0.0            0  Frankfurt   \n",
       "\n",
       "   population  Berlin_data_onlycenter_  \n",
       "0    9.014051                      NaN  \n",
       "1    0.000000                      NaN  \n",
       "2    9.014051                      NaN  \n",
       "3    9.014051                      NaN  \n",
       "4    0.000000                      NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: (10824, 22)\n",
      "data size after dropping na: (10129, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>city</th>\n",
       "      <th>EV_stations</th>\n",
       "      <th>parking</th>\n",
       "      <th>edges</th>\n",
       "      <th>parking_space</th>\n",
       "      <th>civic</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>park</th>\n",
       "      <th>school</th>\n",
       "      <th>...</th>\n",
       "      <th>place_of_worship</th>\n",
       "      <th>university</th>\n",
       "      <th>cinema</th>\n",
       "      <th>library</th>\n",
       "      <th>commercial</th>\n",
       "      <th>retail</th>\n",
       "      <th>townhall</th>\n",
       "      <th>government</th>\n",
       "      <th>residential</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((8.4727605 50.099822499999995, 8.4730...</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.014051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((8.4775730092433 50.10302720327834, 8...</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((8.479750879173663 50.09863320231676,...</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.014051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((8.479688060978736 50.10443297769501,...</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.014051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((8.47965547981383 50.107440331063444,...</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry       city  EV_stations   \n",
       "0  POLYGON ((8.4727605 50.099822499999995, 8.4730...  Frankfurt            0  \\\n",
       "1  POLYGON ((8.4775730092433 50.10302720327834, 8...  Frankfurt            0   \n",
       "2  POLYGON ((8.479750879173663 50.09863320231676,...  Frankfurt            0   \n",
       "3  POLYGON ((8.479688060978736 50.10443297769501,...  Frankfurt            0   \n",
       "4  POLYGON ((8.47965547981383 50.107440331063444,...  Frankfurt            0   \n",
       "\n",
       "   parking  edges  parking_space  civic  restaurant  park  school  ...   \n",
       "0        0      0              0      0           0     0       0  ...  \\\n",
       "1        0      0              0      0           0     0       0  ...   \n",
       "2        0      0              0      0           0     0       0  ...   \n",
       "3        0      0              0      0           0     0       0  ...   \n",
       "4        0      0              0      0           0     0       0  ...   \n",
       "\n",
       "   place_of_worship  university  cinema  library  commercial  retail   \n",
       "0                 0           0       0        0           0       0  \\\n",
       "1                 0           0       0        0           0       0   \n",
       "2                 0           0       0        0           0       0   \n",
       "3                 0           0       0        0           0       0   \n",
       "4                 0           0       0        0           0       0   \n",
       "\n",
       "   townhall  government  residential  population  \n",
       "0         0         0.0            0    9.014051  \n",
       "1         0         0.0            0    0.000000  \n",
       "2         0         0.0            0    9.014051  \n",
       "3         0         0.0            0    9.014051  \n",
       "4         0         0.0            0    0.000000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtering out columsn to be used for modeling\n",
    "data = data[['geometry','city','EV_stations', 'parking', 'edges',\n",
    "        'parking_space', 'civic', 'restaurant', 'park', 'school',\n",
    "       'node', 'Community_centre', 'place_of_worship', 'university', 'cinema',\n",
    "       'library', 'commercial', 'retail', 'townhall', 'government',\n",
    "       'residential', 'population']]\n",
    "print(\"data size:\" , data.shape)\n",
    "data = data.dropna()\n",
    "print(\"data size after dropping na:\" , data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splitter(data, train_cities=None, test_cities=None, test_size=0.2, random_state=42):\n",
    "\n",
    "    if train_cities is not None:\n",
    "        train = data[data['city'].isin(train_cities)]\n",
    "        test = data[data['city'].isin(test_cities)]\n",
    "\n",
    "\n",
    "        X_train = train.drop(['city','geometry', 'EV_stations'], axis=1)\n",
    "        y_train = train['EV_stations'].astype(int)\n",
    "        y_train = y_train.apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "        X_test = test.drop(['city','geometry', 'EV_stations'], axis=1)\n",
    "        y_test = test['EV_stations'].astype(int)\n",
    "        y_test = y_test.apply(lambda x: 1 if x > 0 else 0)\n",
    "    else:\n",
    "        X = data.drop(['city','geometry', \"EV_stations\"], axis=1)\n",
    "        y = data['EV_stations']\n",
    "        y = y.apply(lambda x: 1 if x > 0 else 0)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_splitter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy:  0.8958538993089832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      1786\n",
      "           1       0.62      0.30      0.41       240\n",
      "\n",
      "    accuracy                           0.90      2026\n",
      "   macro avg       0.77      0.64      0.68      2026\n",
      "weighted avg       0.88      0.90      0.88      2026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# logistic regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Logistic Regression Test Accuracy: \", logreg.score(X_test, y_test))\n",
    "# classification report\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b9b40944cb435f923bc596bce9a513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 7 is out of bounds for axis 1 with size 7\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for KNeighborsClassifier: 'Flags' object has no attribute 'c_contiguous'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([   0,    1,    2, ..., 2022, 2023, 2025], dtype=int64), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "                             Model  Accuracy  Precision    Recall  F1-score   \n",
      "12  HistGradientBoostingClassifier  0.900296   0.767657  0.705403  0.730580  \\\n",
      "0               AdaBoostClassifier  0.900296   0.768031  0.703600  0.729434   \n",
      "11      GradientBoostingClassifier  0.899309   0.766435  0.694023  0.722009   \n",
      "25          RandomForestClassifier  0.903258   0.785986  0.685442  0.720676   \n",
      "19                   MLPClassifier  0.900790   0.776544  0.680436  0.714209   \n",
      "15      LinearDiscriminantAnalysis  0.894373   0.750447  0.680403  0.707106   \n",
      "8             ExtraTreesClassifier  0.898815   0.770472  0.672102  0.705814   \n",
      "1                BaggingClassifier  0.891905   0.742488  0.671790  0.698280   \n",
      "9                       GaussianNB  0.866239   0.687214  0.707727  0.696568   \n",
      "20                   MultinomialNB  0.872162   0.693752  0.693052  0.693401   \n",
      "4                     ComplementNB  0.855874   0.674136  0.712668  0.689998   \n",
      "24   QuadraticDiscriminantAnalysis  0.861797   0.677888  0.697994  0.687014   \n",
      "2                      BernoulliNB  0.814413   0.658937  0.777517  0.684522   \n",
      "3           CalibratedClassifierCV  0.898322   0.780082  0.644772  0.682806   \n",
      "18            LogisticRegressionCV  0.896841   0.771005  0.645735  0.682214   \n",
      "17              LogisticRegression  0.895854   0.768226  0.639765  0.675930   \n",
      "21                 NearestCentroid  0.794176   0.654741  0.796697  0.675566   \n",
      "5           DecisionTreeClassifier  0.857848   0.665907  0.677720  0.671459   \n",
      "26                 RidgeClassifier  0.897828   0.791270  0.624655  0.663200   \n",
      "27               RidgeClassifierCV  0.897335   0.789299  0.622571  0.660651   \n",
      "7              ExtraTreeClassifier  0.852912   0.652156  0.658690  0.655301   \n",
      "10       GaussianProcessClassifier  0.862290   0.660018  0.640566  0.649223   \n",
      "23                      Perceptron  0.880059   0.694345  0.594739  0.619051   \n",
      "29                             SVC  0.891905   0.780540  0.583424  0.611760   \n",
      "22     PassiveAggressiveClassifier  0.895360   0.839140  0.578170  0.606306   \n",
      "28                   SGDClassifier  0.695953   0.621081  0.777053  0.601589   \n",
      "16                       LinearSVC  0.888944   0.845027  0.540267  0.545765   \n",
      "13                LabelPropagation  0.848963   0.519835  0.508574  0.503470   \n",
      "14                  LabelSpreading  0.848963   0.519835  0.508574  0.503470   \n",
      "6                  DummyClassifier  0.881540   0.440770  0.500000  0.468520   \n",
      "\n",
      "         AUC  Balanced Accuracy  \n",
      "12  0.705403           0.705403  \n",
      "0   0.703600           0.703600  \n",
      "11  0.694023           0.694023  \n",
      "25  0.685442           0.685442  \n",
      "19  0.680436           0.680436  \n",
      "15  0.680403           0.680403  \n",
      "8   0.672102           0.672102  \n",
      "1   0.671790           0.671790  \n",
      "9   0.707727           0.707727  \n",
      "20  0.693052           0.693052  \n",
      "4   0.712668           0.712668  \n",
      "24  0.697994           0.697994  \n",
      "2   0.777517           0.777517  \n",
      "3   0.644772           0.644772  \n",
      "18  0.645735           0.645735  \n",
      "17  0.639765           0.639765  \n",
      "21  0.796697           0.796697  \n",
      "5   0.677720           0.677720  \n",
      "26  0.624655           0.624655  \n",
      "27  0.622571           0.622571  \n",
      "7   0.658690           0.658690  \n",
      "10  0.640566           0.640566  \n",
      "23  0.594739           0.594739  \n",
      "29  0.583424           0.583424  \n",
      "22  0.578170           0.578170  \n",
      "28  0.777053           0.777053  \n",
      "16  0.540267           0.540267  \n",
      "13  0.508574           0.508574  \n",
      "14  0.508574           0.508574  \n",
      "6   0.500000           0.500000  \n"
     ]
    }
   ],
   "source": [
    "# Get all classification model classes\n",
    "classifiers = all_estimators(type_filter='classifier')\n",
    "\n",
    "# Initialize result table\n",
    "results = []\n",
    "models = {}\n",
    "# Run models and collect results\n",
    "for name, ClassifierClass in tqdm(classifiers):\n",
    "    try:\n",
    "        # Initialize model\n",
    "        model = ClassifierClass()\n",
    "        model.fit(X_train, y_train)\n",
    "        models[name] = model\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='macro')\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results\n",
    "        results.append([name, accuracy, precision, recall, f1, auc, balanced_accuracy])\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for {name}: {str(e)}\")\n",
    "\n",
    "# Create a DataFrame from results\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"AUC\", \"Balanced Accuracy\"])\n",
    "results_df = results_df.sort_values(by=['F1-score', 'AUC'], ascending=False)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X_train, X_test, y_train, y_test):\n",
    "    # Get all classification model classes\n",
    "    classifiers = all_estimators(type_filter='classifier')\n",
    "\n",
    "    # Initialize result table\n",
    "    results = []\n",
    "    models = {}\n",
    "    # Run models and collect results\n",
    "    for name, ClassifierClass in tqdm(classifiers):\n",
    "        try:\n",
    "            # Initialize model\n",
    "            model = ClassifierClass()\n",
    "            model.fit(X_train, y_train)\n",
    "            models[name] = model\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "            balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            # Append results\n",
    "            results.append([name, accuracy, precision, recall, f1, auc, balanced_accuracy])\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred for {name}: {str(e)}\")\n",
    "\n",
    "    # Create a DataFrame from results\n",
    "    results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"AUC\", \"Balanced Accuracy\"])\n",
    "    results_df = results_df.sort_values(by=['F1-score', 'AUC'], ascending=False)\n",
    "    return results_df, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431cc765925b408eb50d63d9f15155c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 7 is out of bounds for axis 1 with size 7\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for KNeighborsClassifier: 'Flags' object has no attribute 'c_contiguous'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([   0,    1,    2, ..., 2022, 2023, 2025], dtype=int64), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "result_df, models = run_experiment(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.900296</td>\n",
       "      <td>0.767657</td>\n",
       "      <td>0.705403</td>\n",
       "      <td>0.730580</td>\n",
       "      <td>0.705403</td>\n",
       "      <td>0.705403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.900296</td>\n",
       "      <td>0.768031</td>\n",
       "      <td>0.703600</td>\n",
       "      <td>0.729434</td>\n",
       "      <td>0.703600</td>\n",
       "      <td>0.703600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.899309</td>\n",
       "      <td>0.766435</td>\n",
       "      <td>0.694023</td>\n",
       "      <td>0.722009</td>\n",
       "      <td>0.694023</td>\n",
       "      <td>0.694023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.903258</td>\n",
       "      <td>0.785986</td>\n",
       "      <td>0.685442</td>\n",
       "      <td>0.720676</td>\n",
       "      <td>0.685442</td>\n",
       "      <td>0.685442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.900790</td>\n",
       "      <td>0.776544</td>\n",
       "      <td>0.680436</td>\n",
       "      <td>0.714209</td>\n",
       "      <td>0.680436</td>\n",
       "      <td>0.680436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.894373</td>\n",
       "      <td>0.750447</td>\n",
       "      <td>0.680403</td>\n",
       "      <td>0.707106</td>\n",
       "      <td>0.680403</td>\n",
       "      <td>0.680403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.898815</td>\n",
       "      <td>0.770472</td>\n",
       "      <td>0.672102</td>\n",
       "      <td>0.705814</td>\n",
       "      <td>0.672102</td>\n",
       "      <td>0.672102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.891905</td>\n",
       "      <td>0.742488</td>\n",
       "      <td>0.671790</td>\n",
       "      <td>0.698280</td>\n",
       "      <td>0.671790</td>\n",
       "      <td>0.671790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.866239</td>\n",
       "      <td>0.687214</td>\n",
       "      <td>0.707727</td>\n",
       "      <td>0.696568</td>\n",
       "      <td>0.707727</td>\n",
       "      <td>0.707727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.872162</td>\n",
       "      <td>0.693752</td>\n",
       "      <td>0.693052</td>\n",
       "      <td>0.693401</td>\n",
       "      <td>0.693052</td>\n",
       "      <td>0.693052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.855874</td>\n",
       "      <td>0.674136</td>\n",
       "      <td>0.712668</td>\n",
       "      <td>0.689998</td>\n",
       "      <td>0.712668</td>\n",
       "      <td>0.712668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.861797</td>\n",
       "      <td>0.677888</td>\n",
       "      <td>0.697994</td>\n",
       "      <td>0.687014</td>\n",
       "      <td>0.697994</td>\n",
       "      <td>0.697994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.814413</td>\n",
       "      <td>0.658937</td>\n",
       "      <td>0.777517</td>\n",
       "      <td>0.684522</td>\n",
       "      <td>0.777517</td>\n",
       "      <td>0.777517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CalibratedClassifierCV</td>\n",
       "      <td>0.898322</td>\n",
       "      <td>0.780082</td>\n",
       "      <td>0.644772</td>\n",
       "      <td>0.682806</td>\n",
       "      <td>0.644772</td>\n",
       "      <td>0.644772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.896841</td>\n",
       "      <td>0.771005</td>\n",
       "      <td>0.645735</td>\n",
       "      <td>0.682214</td>\n",
       "      <td>0.645735</td>\n",
       "      <td>0.645735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.895854</td>\n",
       "      <td>0.768226</td>\n",
       "      <td>0.639765</td>\n",
       "      <td>0.675930</td>\n",
       "      <td>0.639765</td>\n",
       "      <td>0.639765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>0.794176</td>\n",
       "      <td>0.654741</td>\n",
       "      <td>0.796697</td>\n",
       "      <td>0.675566</td>\n",
       "      <td>0.796697</td>\n",
       "      <td>0.796697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.857848</td>\n",
       "      <td>0.665907</td>\n",
       "      <td>0.677720</td>\n",
       "      <td>0.671459</td>\n",
       "      <td>0.677720</td>\n",
       "      <td>0.677720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.897828</td>\n",
       "      <td>0.791270</td>\n",
       "      <td>0.624655</td>\n",
       "      <td>0.663200</td>\n",
       "      <td>0.624655</td>\n",
       "      <td>0.624655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>0.897335</td>\n",
       "      <td>0.789299</td>\n",
       "      <td>0.622571</td>\n",
       "      <td>0.660651</td>\n",
       "      <td>0.622571</td>\n",
       "      <td>0.622571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.852912</td>\n",
       "      <td>0.652156</td>\n",
       "      <td>0.658690</td>\n",
       "      <td>0.655301</td>\n",
       "      <td>0.658690</td>\n",
       "      <td>0.658690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>0.862290</td>\n",
       "      <td>0.660018</td>\n",
       "      <td>0.640566</td>\n",
       "      <td>0.649223</td>\n",
       "      <td>0.640566</td>\n",
       "      <td>0.640566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.880059</td>\n",
       "      <td>0.694345</td>\n",
       "      <td>0.594739</td>\n",
       "      <td>0.619051</td>\n",
       "      <td>0.594739</td>\n",
       "      <td>0.594739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.891905</td>\n",
       "      <td>0.780540</td>\n",
       "      <td>0.583424</td>\n",
       "      <td>0.611760</td>\n",
       "      <td>0.583424</td>\n",
       "      <td>0.583424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>0.895360</td>\n",
       "      <td>0.839140</td>\n",
       "      <td>0.578170</td>\n",
       "      <td>0.606306</td>\n",
       "      <td>0.578170</td>\n",
       "      <td>0.578170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.695953</td>\n",
       "      <td>0.621081</td>\n",
       "      <td>0.777053</td>\n",
       "      <td>0.601589</td>\n",
       "      <td>0.777053</td>\n",
       "      <td>0.777053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.888944</td>\n",
       "      <td>0.845027</td>\n",
       "      <td>0.540267</td>\n",
       "      <td>0.545765</td>\n",
       "      <td>0.540267</td>\n",
       "      <td>0.540267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LabelPropagation</td>\n",
       "      <td>0.848963</td>\n",
       "      <td>0.519835</td>\n",
       "      <td>0.508574</td>\n",
       "      <td>0.503470</td>\n",
       "      <td>0.508574</td>\n",
       "      <td>0.508574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LabelSpreading</td>\n",
       "      <td>0.848963</td>\n",
       "      <td>0.519835</td>\n",
       "      <td>0.508574</td>\n",
       "      <td>0.503470</td>\n",
       "      <td>0.508574</td>\n",
       "      <td>0.508574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.881540</td>\n",
       "      <td>0.440770</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.468520</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy  Precision    Recall  F1-score   \n",
       "12  HistGradientBoostingClassifier  0.900296   0.767657  0.705403  0.730580  \\\n",
       "0               AdaBoostClassifier  0.900296   0.768031  0.703600  0.729434   \n",
       "11      GradientBoostingClassifier  0.899309   0.766435  0.694023  0.722009   \n",
       "25          RandomForestClassifier  0.903258   0.785986  0.685442  0.720676   \n",
       "19                   MLPClassifier  0.900790   0.776544  0.680436  0.714209   \n",
       "15      LinearDiscriminantAnalysis  0.894373   0.750447  0.680403  0.707106   \n",
       "8             ExtraTreesClassifier  0.898815   0.770472  0.672102  0.705814   \n",
       "1                BaggingClassifier  0.891905   0.742488  0.671790  0.698280   \n",
       "9                       GaussianNB  0.866239   0.687214  0.707727  0.696568   \n",
       "20                   MultinomialNB  0.872162   0.693752  0.693052  0.693401   \n",
       "4                     ComplementNB  0.855874   0.674136  0.712668  0.689998   \n",
       "24   QuadraticDiscriminantAnalysis  0.861797   0.677888  0.697994  0.687014   \n",
       "2                      BernoulliNB  0.814413   0.658937  0.777517  0.684522   \n",
       "3           CalibratedClassifierCV  0.898322   0.780082  0.644772  0.682806   \n",
       "18            LogisticRegressionCV  0.896841   0.771005  0.645735  0.682214   \n",
       "17              LogisticRegression  0.895854   0.768226  0.639765  0.675930   \n",
       "21                 NearestCentroid  0.794176   0.654741  0.796697  0.675566   \n",
       "5           DecisionTreeClassifier  0.857848   0.665907  0.677720  0.671459   \n",
       "26                 RidgeClassifier  0.897828   0.791270  0.624655  0.663200   \n",
       "27               RidgeClassifierCV  0.897335   0.789299  0.622571  0.660651   \n",
       "7              ExtraTreeClassifier  0.852912   0.652156  0.658690  0.655301   \n",
       "10       GaussianProcessClassifier  0.862290   0.660018  0.640566  0.649223   \n",
       "23                      Perceptron  0.880059   0.694345  0.594739  0.619051   \n",
       "29                             SVC  0.891905   0.780540  0.583424  0.611760   \n",
       "22     PassiveAggressiveClassifier  0.895360   0.839140  0.578170  0.606306   \n",
       "28                   SGDClassifier  0.695953   0.621081  0.777053  0.601589   \n",
       "16                       LinearSVC  0.888944   0.845027  0.540267  0.545765   \n",
       "13                LabelPropagation  0.848963   0.519835  0.508574  0.503470   \n",
       "14                  LabelSpreading  0.848963   0.519835  0.508574  0.503470   \n",
       "6                  DummyClassifier  0.881540   0.440770  0.500000  0.468520   \n",
       "\n",
       "         AUC  Balanced Accuracy  \n",
       "12  0.705403           0.705403  \n",
       "0   0.703600           0.703600  \n",
       "11  0.694023           0.694023  \n",
       "25  0.685442           0.685442  \n",
       "19  0.680436           0.680436  \n",
       "15  0.680403           0.680403  \n",
       "8   0.672102           0.672102  \n",
       "1   0.671790           0.671790  \n",
       "9   0.707727           0.707727  \n",
       "20  0.693052           0.693052  \n",
       "4   0.712668           0.712668  \n",
       "24  0.697994           0.697994  \n",
       "2   0.777517           0.777517  \n",
       "3   0.644772           0.644772  \n",
       "18  0.645735           0.645735  \n",
       "17  0.639765           0.639765  \n",
       "21  0.796697           0.796697  \n",
       "5   0.677720           0.677720  \n",
       "26  0.624655           0.624655  \n",
       "27  0.622571           0.622571  \n",
       "7   0.658690           0.658690  \n",
       "10  0.640566           0.640566  \n",
       "23  0.594739           0.594739  \n",
       "29  0.583424           0.583424  \n",
       "22  0.578170           0.578170  \n",
       "28  0.777053           0.777053  \n",
       "16  0.540267           0.540267  \n",
       "13  0.508574           0.508574  \n",
       "14  0.508574           0.508574  \n",
       "6   0.500000           0.500000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"../results/all_cities_random_shuffle.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4224b75a67fa4314ac84d1c131cc71ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b709d665adb34d63a490a712cc6c8bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 51 is out of bounds for axis 1 with size 51\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for KNeighborsClassifier: 'Flags' object has no attribute 'c_contiguous'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([   2,    9,   17, ..., 3877, 3878, 3879], dtype=int64), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6307445d16204ae3a1aacabc6c8d1d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 53 is out of bounds for axis 1 with size 48\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for KNeighborsClassifier: 'Flags' object has no attribute 'c_contiguous'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([  15,   17,   22, ..., 1409, 1410, 1420], dtype=int64), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8ee4192d62418e874da2f853f6e0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 13 is out of bounds for axis 1 with size 10\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for KNeighborsClassifier: 'Flags' object has no attribute 'c_contiguous'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([ 11,  20,  21,  23,  27,  30,  31,  32,  39,  40,  41,  42,  43,\n",
      "        44,  45,  46,  49,  50,  51,  52,  54,  55,  56,  57,  58,  59,\n",
      "        64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  77,\n",
      "        79,  80,  81,  82,  84,  85,  86,  95,  98,  99, 100, 101, 102,\n",
      "       103, 104, 106, 107, 108, 109, 110, 111, 112, 119, 122, 123, 124,\n",
      "       125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137,\n",
      "       138, 139, 144, 147, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "       159, 162, 163, 164, 165, 166, 167, 171, 172, 173, 174, 175, 176,\n",
      "       177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190, 191,\n",
      "       192, 193, 198, 199, 200, 201, 202, 203, 206, 207, 208, 209, 210,\n",
      "       211, 212, 213, 216, 219, 220, 225, 226, 227, 228, 230, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 246, 248, 250, 251, 252, 253,\n",
      "       256, 257, 258, 259, 260, 261, 263, 264, 265, 266, 267, 268, 269,\n",
      "       270, 271, 272, 274, 275, 277, 278, 280, 281, 282, 285, 286, 287,\n",
      "       288, 289, 290, 292, 293, 294, 295, 296, 297, 298, 299, 301, 302,\n",
      "       303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
      "       316, 317, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
      "       330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
      "       343, 344, 346, 347, 348, 349, 350, 351, 352, 354, 355, 356, 357,\n",
      "       358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370,\n",
      "       371, 372, 373, 374, 375, 376, 377, 378, 379, 381, 382, 383, 384,\n",
      "       385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397,\n",
      "       398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410,\n",
      "       411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423,\n",
      "       424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436,\n",
      "       437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 450,\n",
      "       451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
      "       464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 477, 484,\n",
      "       485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497,\n",
      "       498, 499, 500, 501, 502, 503, 505, 506, 507, 509, 511, 512, 521,\n",
      "       522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534,\n",
      "       535, 536, 537, 538, 540, 541, 542, 547, 548, 549, 553, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 577, 578, 579, 581, 582, 583, 585, 586, 589, 590,\n",
      "       594, 595, 596, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607,\n",
      "       608, 609, 610, 611, 612, 613, 616, 617, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 632, 633, 634, 635, 636, 637, 638, 639,\n",
      "       640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 652, 654,\n",
      "       655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667,\n",
      "       669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681,\n",
      "       682, 683, 684, 685, 686, 687, 688, 689, 691, 692, 693, 694, 695,\n",
      "       696, 697, 699, 701, 703, 704, 705, 706, 707, 708, 709, 710, 711,\n",
      "       712, 713, 714, 715, 716, 717, 718, 719, 720, 722, 723, 724, 725,\n",
      "       727, 728, 729, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743,\n",
      "       744, 745, 746, 747, 748, 749, 750, 751, 752, 754, 755, 757, 758,\n",
      "       759, 760, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772,\n",
      "       773, 774, 775, 776, 777, 778, 779, 780, 782, 783, 784, 785, 786,\n",
      "       794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806,\n",
      "       808, 809, 810, 812, 813, 814, 815, 816, 823, 824, 825, 826, 827,\n",
      "       828, 829, 830, 831, 832, 836, 837, 838, 839, 840, 841, 842, 843,\n",
      "       844, 845, 846, 847, 848, 850, 851, 853, 854, 855, 856, 857, 858,\n",
      "       859, 861, 863, 864, 865, 866, 867, 868, 869, 873, 874, 875, 876,\n",
      "       878, 880, 887, 901, 902, 903, 904, 905, 906, 907, 910, 911, 912,\n",
      "       913, 914, 929, 930, 933, 934, 938, 939, 941, 956], dtype=int64), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0877ce64d1864e259c57d63514b7c0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 12 is out of bounds for axis 1 with size 11\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for KNeighborsClassifier: 'Flags' object has no attribute 'c_contiguous'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([   6,   12,   13,   19,   20,   21,   27,   28,   29,   30,   31,\n",
      "         32,   33,   41,   43,   44,   45,   46,   55,   56,   57,   58,\n",
      "         59,   60,   61,   66,   67,   68,   69,   70,   71,   79,   80,\n",
      "         81,   82,   83,   84,   86,   88,   89,   90,   91,   92,   93,\n",
      "         94,   95,   96,   97,  101,  102,  103,  104,  105,  106,  107,\n",
      "        108,  109,  110,  115,  116,  117,  118,  120,  121,  122,  123,\n",
      "        129,  130,  136,  138,  139,  141,  142,  153,  154,  159,  160,\n",
      "        162,  163,  164,  165,  166,  167,  168,  171,  178,  179,  186,\n",
      "        187,  188,  189,  192,  193,  194,  195,  196,  197,  204,  205,\n",
      "        206,  210,  213,  215,  216,  219,  220,  221,  222,  223,  224,\n",
      "        225,  226,  227,  232,  238,  239,  243,  244,  245,  249,  250,\n",
      "        251,  253,  254,  260,  261,  265,  266,  267,  270,  273,  274,\n",
      "        275,  276,  279,  280,  281,  282,  283,  284,  285,  286,  291,\n",
      "        292,  296,  303,  305,  306,  307,  308,  309,  310,  311,  312,\n",
      "        313,  314,  315,  316,  317,  318,  319,  320,  324,  325,  326,\n",
      "        336,  337,  338,  339,  340,  341,  342,  343,  344,  345,  346,\n",
      "        347,  348,  349,  351,  352,  357,  364,  365,  366,  367,  368,\n",
      "        369,  370,  371,  372,  373,  374,  375,  376,  377,  378,  379,\n",
      "        380,  381,  382,  383,  384,  385,  386,  394,  396,  397,  398,\n",
      "        399,  400,  401,  402,  403,  404,  405,  406,  407,  408,  409,\n",
      "        410,  411,  412,  413,  414,  415,  416,  417,  418,  419,  420,\n",
      "        425,  426,  428,  429,  430,  431,  432,  433,  434,  435,  436,\n",
      "        438,  439,  440,  441,  442,  443,  444,  445,  446,  447,  448,\n",
      "        449,  450,  451,  452,  453,  455,  459,  462,  463,  464,  465,\n",
      "        466,  467,  468,  469,  470,  471,  472,  473,  474,  475,  476,\n",
      "        477,  478,  479,  480,  481,  482,  483,  484,  485,  486,  487,\n",
      "        488,  489,  490,  494,  496,  497,  498,  499,  500,  502,  503,\n",
      "        504,  505,  506,  507,  508,  509,  510,  511,  512,  513,  514,\n",
      "        515,  516,  517,  518,  519,  520,  521,  522,  523,  524,  525,\n",
      "        527,  530,  531,  532,  533,  535,  538,  539,  540,  541,  542,\n",
      "        543,  544,  545,  546,  547,  548,  549,  550,  551,  552,  553,\n",
      "        554,  555,  556,  557,  558,  559,  560,  561,  562,  566,  567,\n",
      "        568,  569,  570,  571,  573,  574,  575,  576,  577,  578,  579,\n",
      "        580,  581,  582,  583,  584,  585,  586,  587,  588,  589,  590,\n",
      "        591,  592,  593,  594,  596,  602,  603,  604,  605,  606,  607,\n",
      "        608,  610,  611,  612,  613,  614,  615,  616,  617,  618,  619,\n",
      "        620,  621,  622,  623,  624,  625,  626,  627,  628,  629,  631,\n",
      "        638,  639,  640,  642,  643,  644,  647,  648,  649,  650,  651,\n",
      "        652,  653,  654,  655,  656,  657,  658,  659,  660,  661,  662,\n",
      "        663,  664,  665,  666,  667,  670,  672,  676,  677,  683,  684,\n",
      "        685,  686,  687,  688,  689,  690,  691,  692,  693,  694,  695,\n",
      "        696,  697,  698,  699,  700,  701,  702,  703,  704,  706,  709,\n",
      "        718,  722,  723,  724,  725,  726,  727,  728,  729,  730,  731,\n",
      "        732,  733,  734,  735,  736,  737,  738,  739,  740,  741,  744,\n",
      "        746,  747,  755,  756,  758,  759,  760,  761,  762,  763,  764,\n",
      "        765,  766,  767,  768,  769,  770,  771,  772,  773,  774,  775,\n",
      "        776,  777,  778,  784,  787,  788,  791,  792,  793,  794,  795,\n",
      "        798,  799,  800,  801,  802,  803,  804,  805,  806,  807,  808,\n",
      "        809,  810,  811,  812,  813,  814,  815,  824,  825,  826,  836,\n",
      "        837,  838,  866,  867,  868,  869,  870,  871,  872,  873,  874,\n",
      "        875,  876,  877,  878,  879,  880,  881,  894,  895,  896,  897,\n",
      "        898,  899,  900,  901,  902,  903,  904,  905,  906,  907,  909,\n",
      "        912,  917,  918,  919,  922,  923,  924,  925,  926,  927,  928,\n",
      "        929,  930,  931,  932,  933,  934,  937,  939,  941,  943,  944,\n",
      "        945,  946,  948,  949,  950,  951,  952,  953,  955,  956,  957,\n",
      "        966,  967,  968,  969,  970,  971,  972,  973,  974,  975,  976,\n",
      "        978,  979,  980,  981,  982,  983,  984,  985,  986,  987,  988,\n",
      "        992,  993,  994,  995,  996,  997,  998,  999, 1000, 1001, 1006,\n",
      "       1007, 1008, 1009, 1010, 1012, 1013, 1014, 1015, 1016, 1023, 1024,\n",
      "       1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1040, 1045,\n",
      "       1046, 1047, 1048, 1049, 1050, 1051, 1058, 1063, 1068, 1072, 1084,\n",
      "       1091, 1092, 1093, 1094, 1100, 1105, 1121, 1129, 1130, 1137, 1143,\n",
      "       1145], dtype=int64), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b15a3aa12c940f990cac7c550f170f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3269755f1c6948c5a8cdf48617a79221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for AdaBoostClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by AdaBoostClassifier.\n",
      "Error occurred for BaggingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by BaggingClassifier.\n",
      "Error occurred for BernoulliNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by BernoulliNB.\n",
      "Error occurred for CalibratedClassifierCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearSVC.\n",
      "Error occurred for CategoricalNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by CategoricalNB.\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ComplementNB.\n",
      "Error occurred for DecisionTreeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by DecisionTreeClassifier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for DummyClassifier: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "Error occurred for ExtraTreeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ExtraTreeClassifier.\n",
      "Error occurred for ExtraTreesClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ExtraTreesClassifier.\n",
      "Error occurred for GaussianNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GaussianNB.\n",
      "Error occurred for GaussianProcessClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GaussianProcessClassifier.\n",
      "Error occurred for GradientBoostingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GradientBoostingClassifier.\n",
      "Error occurred for HistGradientBoostingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by HistGradientBoostingClassifier.\n",
      "Error occurred for KNeighborsClassifier: 'Flags' object has no attribute 'c_contiguous'\n",
      "Error occurred for LabelPropagation: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LabelPropagation.\n",
      "Error occurred for LabelSpreading: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LabelSpreading.\n",
      "Error occurred for LinearDiscriminantAnalysis: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearDiscriminantAnalysis.\n",
      "Error occurred for LinearSVC: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearSVC.\n",
      "Error occurred for LogisticRegression: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LogisticRegression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for LogisticRegressionCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LogisticRegressionCV.\n",
      "Error occurred for MLPClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by MLPClassifier.\n",
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by MultinomialNB.\n",
      "Error occurred for NearestCentroid: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by NearestCentroid.\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for PassiveAggressiveClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by PassiveAggressiveClassifier.\n",
      "Error occurred for Perceptron: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by Perceptron.\n",
      "Error occurred for QuadraticDiscriminantAnalysis: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by QuadraticDiscriminantAnalysis.\n",
      "Error occurred for RadiusNeighborsClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RadiusNeighborsClassifier.\n",
      "Error occurred for RandomForestClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RandomForestClassifier.\n",
      "Error occurred for RidgeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RidgeClassifier.\n",
      "Error occurred for RidgeClassifierCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RidgeClassifierCV.\n",
      "Error occurred for SGDClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by SGDClassifier.\n",
      "Error occurred for SVC: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by SVC.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7753e5a51c074add9d24a4eb84a4c18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 87 is out of bounds for axis 1 with size 46\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for KNeighborsClassifier: 'Flags' object has no attribute 'c_contiguous'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([  7,  11,  15,  21,  25,  27,  28,  29,  39,  40,  41,  42,  43,\n",
      "        47,  51,  52,  53,  54,  55,  58,  59,  63,  64,  65,  66,  70,\n",
      "        71,  72,  73,  74,  75,  76,  82,  83,  84,  85,  86,  87,  88,\n",
      "        90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 102, 103, 104,\n",
      "       105, 106, 107, 108, 109, 110, 112, 115, 116, 120, 121, 122, 123,\n",
      "       124, 125, 126, 127, 128, 129, 130, 131, 133, 135, 137, 138, 139,\n",
      "       140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153,\n",
      "       154, 155, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171,\n",
      "       172, 182, 183, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "       196, 197, 208, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "       220, 221, 230, 231, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
      "       245, 246, 247, 248, 262, 263, 264, 265, 266, 267, 268, 269, 270,\n",
      "       271, 272, 273, 275, 279, 284, 285, 288, 290, 291, 292, 293, 294,\n",
      "       295, 296, 297, 298, 299, 300, 301, 302, 303, 319, 320, 324, 325,\n",
      "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
      "       339, 340, 341, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 386,\n",
      "       387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 399, 408,\n",
      "       409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 426, 427, 428,\n",
      "       429, 432, 434, 435, 436, 437, 443, 444, 445, 446, 450, 453, 456,\n",
      "       470, 471, 472, 473, 474, 477, 478, 479, 480, 481, 483, 484, 486,\n",
      "       487, 488, 497, 498, 499, 500, 501, 502, 503, 504, 505, 507, 510,\n",
      "       511, 512, 513, 514, 515, 516, 517, 518, 524, 525, 526, 527, 528,\n",
      "       529, 538, 539, 540, 554, 563, 564, 569, 570, 578, 581, 582],\n",
      "      dtype=int64), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a2bae67e3f422281e95f38fe6c81a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for AdaBoostClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by AdaBoostClassifier.\n",
      "Error occurred for BaggingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by BaggingClassifier.\n",
      "Error occurred for BernoulliNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by BernoulliNB.\n",
      "Error occurred for CalibratedClassifierCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearSVC.\n",
      "Error occurred for CategoricalNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by CategoricalNB.\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Error occurred for ComplementNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ComplementNB.\n",
      "Error occurred for DecisionTreeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by DecisionTreeClassifier.\n",
      "Error occurred for DummyClassifier: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "Error occurred for ExtraTreeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ExtraTreeClassifier.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for ExtraTreesClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by ExtraTreesClassifier.\n",
      "Error occurred for GaussianNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GaussianNB.\n",
      "Error occurred for GaussianProcessClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GaussianProcessClassifier.\n",
      "Error occurred for GradientBoostingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by GradientBoostingClassifier.\n",
      "Error occurred for HistGradientBoostingClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by HistGradientBoostingClassifier.\n",
      "Error occurred for KNeighborsClassifier: 'Flags' object has no attribute 'c_contiguous'\n",
      "Error occurred for LabelPropagation: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LabelPropagation.\n",
      "Error occurred for LabelSpreading: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LabelSpreading.\n",
      "Error occurred for LinearDiscriminantAnalysis: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearDiscriminantAnalysis.\n",
      "Error occurred for LinearSVC: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LinearSVC.\n",
      "Error occurred for LogisticRegression: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LogisticRegression.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for LogisticRegressionCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by LogisticRegressionCV.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MLPClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by MLPClassifier.\n",
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for MultinomialNB: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by MultinomialNB.\n",
      "Error occurred for NearestCentroid: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by NearestCentroid.\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for PassiveAggressiveClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by PassiveAggressiveClassifier.\n",
      "Error occurred for Perceptron: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by Perceptron.\n",
      "Error occurred for QuadraticDiscriminantAnalysis: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by QuadraticDiscriminantAnalysis.\n",
      "Error occurred for RadiusNeighborsClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RadiusNeighborsClassifier.\n",
      "Error occurred for RandomForestClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RandomForestClassifier.\n",
      "Error occurred for RidgeClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RidgeClassifier.\n",
      "Error occurred for RidgeClassifierCV: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by RidgeClassifierCV.\n",
      "Error occurred for SGDClassifier: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by SGDClassifier.\n",
      "Error occurred for SVC: Found array with 0 sample(s) (shape=(0, 19)) while a minimum of 1 is required by SVC.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5554a7f2c0114b848ce2c8c8abd31792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for CategoricalNB: index 47 is out of bounds for axis 1 with size 33\n",
      "Error occurred for ClassifierChain: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for KNeighborsClassifier: 'Flags' object has no attribute 'c_contiguous'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for MultiOutputClassifier: MultiOutputClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for NuSVC: specified nu is infeasible\n",
      "Error occurred for OneVsOneClassifier: OneVsOneClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OneVsRestClassifier: OneVsRestClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for OutputCodeClassifier: OutputCodeClassifier.__init__() missing 1 required positional argument: 'estimator'\n",
      "Error occurred for RadiusNeighborsClassifier: No neighbors found for test samples array([  0,   2,   3,   8,  11,  12,  14,  16,  17,  19,  21,  22,  24,\n",
      "        26,  27,  28,  29,  30,  33,  35,  36,  37,  38,  39,  40,  43,\n",
      "        44,  45,  46,  47,  48,  49,  50,  54,  56,  57,  58,  59,  60,\n",
      "        61,  62,  63,  64,  65,  66,  67,  68,  72,  73,  74,  75,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  86,  87,  89,  90,  91,  92,\n",
      "        93,  94,  95,  97,  98,  99, 101, 102, 104, 105, 106, 107, 108,\n",
      "       110, 111, 112, 113, 114, 115, 116, 120, 121, 122, 125, 126, 127,\n",
      "       128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 140, 141, 142,\n",
      "       146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158,\n",
      "       159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173,\n",
      "       174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 186, 187, 188,\n",
      "       189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201,\n",
      "       202, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217,\n",
      "       218, 219, 220, 221, 222, 231, 232, 233, 236, 238, 239, 240, 241,\n",
      "       242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254,\n",
      "       255, 256, 257, 261, 262, 263, 264, 269, 270, 271, 272, 273, 274,\n",
      "       275, 276, 277, 278, 279, 281, 282, 283, 284, 285, 286, 287, 288,\n",
      "       292, 293, 294, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306,\n",
      "       307, 308, 309, 310, 311, 312, 313, 318, 319, 322, 323, 324, 325,\n",
      "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339,\n",
      "       344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356,\n",
      "       357, 360, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374,\n",
      "       375, 379, 380, 381, 382, 383, 384, 385, 386, 391, 392, 393, 394,\n",
      "       395, 398, 400, 405, 406, 407, 408, 409, 410, 411, 412, 413, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 426, 427, 428, 429, 430,\n",
      "       431, 432, 434, 435, 436, 437, 438, 439, 440, 445, 446, 447, 448,\n",
      "       455, 456, 457, 466, 467, 468, 475, 476, 484, 486, 487], dtype=int64), you can try using larger radius, giving a label for outliers, or considering removing them from your dataset.\n",
      "Error occurred for StackingClassifier: StackingClassifier.__init__() missing 1 required positional argument: 'estimators'\n",
      "Error occurred for VotingClassifier: VotingClassifier.__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh Babu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Berlin, Munich, Stuttgart, Frankfurt: Big CITY EXP-1\n",
    "Kalsruhe, trier, saarbrucken, mainz: EXP-2\n",
    "\"\"\"\n",
    "\n",
    "# EXP-1\n",
    "big_cities = ['Berlin', 'Munich', 'Stuttgart', 'Frankfurt']\n",
    "small_cities = ['Karlsruhe', 'Trier', 'Saarbrücken', 'Mainz']\n",
    "\n",
    "\n",
    "# make a table in the end to summarise the results of all experiments\n",
    "\n",
    "# big cities splited in trian and test where only one big city is test and all possible combinations for this\n",
    "for city in tqdm(big_cities):\n",
    "    test_cities = [city]\n",
    "    train_cities = [x for x in big_cities if x != city]\n",
    "    X_train, X_test, y_train, y_test = data_splitter(data, train_cities=train_cities, test_cities=test_cities)\n",
    "    results_df, models = run_experiment(X_train, X_test, y_train, y_test)\n",
    "    results_df.to_csv(f\"../results/big_cities_test_city_{city}_.csv\", index=False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# small cities splited in trian and test where only one small city is test and all possible combinations for this\n",
    "for city in tqdm(small_cities):\n",
    "    test_cities = [city]\n",
    "    train_cities = [x for x in small_cities if x != city]\n",
    "    X_train, X_test, y_train, y_test = data_splitter(data, train_cities=train_cities, test_cities=test_cities)\n",
    "    results_df, models = run_experiment(X_train, X_test, y_train, y_test)\n",
    "    results_df.to_csv(f\"../results/small_cities_test_city_{city}_.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.847561</td>\n",
       "      <td>0.633567</td>\n",
       "      <td>0.812410</td>\n",
       "      <td>0.665443</td>\n",
       "      <td>0.812410</td>\n",
       "      <td>0.812410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.597812</td>\n",
       "      <td>0.643133</td>\n",
       "      <td>0.597812</td>\n",
       "      <td>0.597812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.626664</td>\n",
       "      <td>0.652892</td>\n",
       "      <td>0.637969</td>\n",
       "      <td>0.652892</td>\n",
       "      <td>0.652892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.912602</td>\n",
       "      <td>0.651632</td>\n",
       "      <td>0.623163</td>\n",
       "      <td>0.635386</td>\n",
       "      <td>0.623163</td>\n",
       "      <td>0.623163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.898675</td>\n",
       "      <td>0.584620</td>\n",
       "      <td>0.626934</td>\n",
       "      <td>0.584620</td>\n",
       "      <td>0.584620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.880081</td>\n",
       "      <td>0.605113</td>\n",
       "      <td>0.645233</td>\n",
       "      <td>0.620127</td>\n",
       "      <td>0.645233</td>\n",
       "      <td>0.645233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.803313</td>\n",
       "      <td>0.582432</td>\n",
       "      <td>0.619342</td>\n",
       "      <td>0.582432</td>\n",
       "      <td>0.582432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.790650</td>\n",
       "      <td>0.606883</td>\n",
       "      <td>0.808159</td>\n",
       "      <td>0.617548</td>\n",
       "      <td>0.808159</td>\n",
       "      <td>0.808159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>0.676409</td>\n",
       "      <td>0.589059</td>\n",
       "      <td>0.614229</td>\n",
       "      <td>0.589059</td>\n",
       "      <td>0.589059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.969199</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.609110</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.912602</td>\n",
       "      <td>0.629304</td>\n",
       "      <td>0.583589</td>\n",
       "      <td>0.599614</td>\n",
       "      <td>0.583589</td>\n",
       "      <td>0.583589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.930894</td>\n",
       "      <td>0.746722</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.595551</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.567052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RidgeClassifierCV</td>\n",
       "      <td>0.930894</td>\n",
       "      <td>0.746722</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.595551</td>\n",
       "      <td>0.567052</td>\n",
       "      <td>0.567052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>0.760163</td>\n",
       "      <td>0.597732</td>\n",
       "      <td>0.804939</td>\n",
       "      <td>0.595338</td>\n",
       "      <td>0.804939</td>\n",
       "      <td>0.804939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.636076</td>\n",
       "      <td>0.572585</td>\n",
       "      <td>0.591188</td>\n",
       "      <td>0.572585</td>\n",
       "      <td>0.572585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegressionCV</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.627239</td>\n",
       "      <td>0.571491</td>\n",
       "      <td>0.588530</td>\n",
       "      <td>0.571491</td>\n",
       "      <td>0.571491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>0.908537</td>\n",
       "      <td>0.605513</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.580991</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.908537</td>\n",
       "      <td>0.605513</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.580991</td>\n",
       "      <td>0.568209</td>\n",
       "      <td>0.568209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.932927</td>\n",
       "      <td>0.801440</td>\n",
       "      <td>0.554955</td>\n",
       "      <td>0.580064</td>\n",
       "      <td>0.554955</td>\n",
       "      <td>0.554955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.635220</td>\n",
       "      <td>0.560488</td>\n",
       "      <td>0.578587</td>\n",
       "      <td>0.560488</td>\n",
       "      <td>0.560488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>QuadraticDiscriminantAnalysis</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>0.649594</td>\n",
       "      <td>0.549484</td>\n",
       "      <td>0.566701</td>\n",
       "      <td>0.549484</td>\n",
       "      <td>0.549484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CalibratedClassifierCV</td>\n",
       "      <td>0.934959</td>\n",
       "      <td>0.967280</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.562034</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.898374</td>\n",
       "      <td>0.567880</td>\n",
       "      <td>0.549547</td>\n",
       "      <td>0.556277</td>\n",
       "      <td>0.549547</td>\n",
       "      <td>0.549547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HistGradientBoostingClassifier</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.681296</td>\n",
       "      <td>0.538481</td>\n",
       "      <td>0.552320</td>\n",
       "      <td>0.538481</td>\n",
       "      <td>0.538481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.666119</td>\n",
       "      <td>0.525289</td>\n",
       "      <td>0.530932</td>\n",
       "      <td>0.525289</td>\n",
       "      <td>0.525289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.928862</td>\n",
       "      <td>0.464431</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.481560</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.928862</td>\n",
       "      <td>0.464431</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.481560</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.928862</td>\n",
       "      <td>0.464431</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.481560</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LabelPropagation</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.464358</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>0.498906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LabelSpreading</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.464358</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.498906</td>\n",
       "      <td>0.498906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Accuracy  Precision    Recall  F1-score   \n",
       "2                      BernoulliNB  0.847561   0.633567  0.812410  0.665443  \\\n",
       "28                   SGDClassifier  0.939024   0.859903  0.597812  0.643133   \n",
       "20                   MultinomialNB  0.894309   0.626664  0.652892  0.637969   \n",
       "17              LogisticRegression  0.912602   0.651632  0.623163  0.635386   \n",
       "8             ExtraTreesClassifier  0.939024   0.898675  0.584620  0.626934   \n",
       "4                     ComplementNB  0.880081   0.605113  0.645233  0.620127   \n",
       "25          RandomForestClassifier  0.934959   0.803313  0.582432  0.619342   \n",
       "16                       LinearSVC  0.790650   0.606883  0.808159  0.617548   \n",
       "0               AdaBoostClassifier  0.922764   0.676409  0.589059  0.614229   \n",
       "22     PassiveAggressiveClassifier  0.939024   0.969199  0.571429  0.609110   \n",
       "5           DecisionTreeClassifier  0.912602   0.629304  0.583589  0.599614   \n",
       "26                 RidgeClassifier  0.930894   0.746722  0.567052  0.595551   \n",
       "27               RidgeClassifierCV  0.930894   0.746722  0.567052  0.595551   \n",
       "21                 NearestCentroid  0.760163   0.597732  0.804939  0.595338   \n",
       "1                BaggingClassifier  0.916667   0.636076  0.572585  0.591188   \n",
       "18            LogisticRegressionCV  0.914634   0.627239  0.571491  0.588530   \n",
       "10       GaussianProcessClassifier  0.908537   0.605513  0.568209  0.580991   \n",
       "15      LinearDiscriminantAnalysis  0.908537   0.605513  0.568209  0.580991   \n",
       "23                      Perceptron  0.932927   0.801440  0.554955  0.580064   \n",
       "11      GradientBoostingClassifier  0.918699   0.635220  0.560488  0.578587   \n",
       "24   QuadraticDiscriminantAnalysis  0.922764   0.649594  0.549484  0.566701   \n",
       "3           CalibratedClassifierCV  0.934959   0.967280  0.542857  0.562034   \n",
       "7              ExtraTreeClassifier  0.898374   0.567880  0.549547  0.556277   \n",
       "12  HistGradientBoostingClassifier  0.926829   0.681296  0.538481  0.552320   \n",
       "19                   MLPClassifier  0.926829   0.666119  0.525289  0.530932   \n",
       "6                  DummyClassifier  0.928862   0.464431  0.500000  0.481560   \n",
       "9                       GaussianNB  0.928862   0.464431  0.500000  0.481560   \n",
       "29                             SVC  0.928862   0.464431  0.500000  0.481560   \n",
       "13                LabelPropagation  0.926829   0.464358  0.498906  0.481013   \n",
       "14                  LabelSpreading  0.926829   0.464358  0.498906  0.481013   \n",
       "\n",
       "         AUC  Balanced Accuracy  \n",
       "2   0.812410           0.812410  \n",
       "28  0.597812           0.597812  \n",
       "20  0.652892           0.652892  \n",
       "17  0.623163           0.623163  \n",
       "8   0.584620           0.584620  \n",
       "4   0.645233           0.645233  \n",
       "25  0.582432           0.582432  \n",
       "16  0.808159           0.808159  \n",
       "0   0.589059           0.589059  \n",
       "22  0.571429           0.571429  \n",
       "5   0.583589           0.583589  \n",
       "26  0.567052           0.567052  \n",
       "27  0.567052           0.567052  \n",
       "21  0.804939           0.804939  \n",
       "1   0.572585           0.572585  \n",
       "18  0.571491           0.571491  \n",
       "10  0.568209           0.568209  \n",
       "15  0.568209           0.568209  \n",
       "23  0.554955           0.554955  \n",
       "11  0.560488           0.560488  \n",
       "24  0.549484           0.549484  \n",
       "3   0.542857           0.542857  \n",
       "7   0.549547           0.549547  \n",
       "12  0.538481           0.538481  \n",
       "19  0.525289           0.525289  \n",
       "6   0.500000           0.500000  \n",
       "9   0.500000           0.500000  \n",
       "29  0.500000           0.500000  \n",
       "13  0.498906           0.498906  \n",
       "14  0.498906           0.498906  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results\\all_cities_random_shuffle.csv\n",
      "../results\\big_cities_test_city_Berlin_.csv\n",
      "../results\\big_cities_test_city_Frankfurt_.csv\n",
      "../results\\big_cities_test_city_Munich_.csv\n",
      "../results\\big_cities_test_city_Stuttgart_.csv\n",
      "../results\\small_cities_test_city_Karlsruhe_.csv\n",
      "../results\\small_cities_test_city_Mainz_.csv\n",
      "../results\\small_cities_test_city_Saarbrücken_.csv\n",
      "../results\\small_cities_test_city_Trier_.csv\n",
      "              Model  Average AUC\n",
      "12      BernoulliNB     0.779203\n",
      "16  NearestCentroid     0.766557\n",
      "10     ComplementNB     0.671147\n",
      "9     MultinomialNB     0.662987\n",
      "25    SGDClassifier     0.658037\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get a list of all result files from different experiments\n",
    "result_files = glob.glob(\"../results/*.csv\")\n",
    "\n",
    "# Create a dictionary to store the total AUC and count for each model\n",
    "auc_sum_per_model = {}\n",
    "count_per_model = {}\n",
    "\n",
    "# Iterate over each result file\n",
    "for file in result_files:\n",
    "    print(file)\n",
    "    # Load the results for each experiment\n",
    "    results = pd.read_csv(file)\n",
    "    \n",
    "    # Iterate over each row in the results\n",
    "    for _, row in results.iterrows():\n",
    "        model = row['Model']\n",
    "        auc = row['AUC']\n",
    "        \n",
    "        # Update the total AUC and count for the model\n",
    "        if model in auc_sum_per_model:\n",
    "            auc_sum_per_model[model] += auc\n",
    "            count_per_model[model] += 1\n",
    "        else:\n",
    "            auc_sum_per_model[model] = auc\n",
    "            count_per_model[model] = 1\n",
    "\n",
    "# Calculate the average AUC for each model\n",
    "average_auc_per_model = {model: auc_sum_per_model[model] / count_per_model[model] for model in auc_sum_per_model}\n",
    "\n",
    "# Create a DataFrame from the average AUC dictionary\n",
    "average_auc_df = pd.DataFrame(list(average_auc_per_model.items()), columns=['Model', 'Average AUC'])\n",
    "\n",
    "# Sort the DataFrame by Average AUC in descending order\n",
    "sorted_models = average_auc_df.sort_values(by='Average AUC', ascending=False)\n",
    "\n",
    "# Select the top 5 models\n",
    "top_5_models = sorted_models.head(5)\n",
    "\n",
    "# Display the best models\n",
    "print(top_5_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.779203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>0.766557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ComplementNB</td>\n",
       "      <td>0.671147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.662987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.658037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  Average AUC\n",
       "12      BernoulliNB     0.779203\n",
       "16  NearestCentroid     0.766557\n",
       "10     ComplementNB     0.671147\n",
       "9     MultinomialNB     0.662987\n",
       "25    SGDClassifier     0.658037"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  type_city  BernoulliNB  ComplementNB  GaussianNB  NearestCentroid   \n",
      "0       big     0.764115      0.669090    0.660482         0.715620  \\\n",
      "1     small     0.810223      0.654498         NaN         0.853362   \n",
      "2       all     0.799321      0.673888         NaN         0.834474   \n",
      "\n",
      "   QuadraticDiscriminantAnalysis  LinearSVC  MultinomialNB  SGDClassifier  \n",
      "0                       0.657869        NaN            NaN            NaN  \n",
      "1                            NaN   0.685329       0.666221            NaN  \n",
      "2                            NaN        NaN       0.675165       0.676748  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get a list of all result files from different experiments\n",
    "result_files = glob.glob(\"../results/*.csv\")\n",
    "\n",
    "# Create an empty DataFrame to store the combined results\n",
    "combined_results = pd.DataFrame()\n",
    "\n",
    "# Create an empty DataFrame to store the summary\n",
    "summary_results = pd.DataFrame(columns=['type_city'])\n",
    "\n",
    "# Iterate over each result file\n",
    "for type_city in ['big', 'small', 'all']:\n",
    "    # Reset combined_results for each type_city iteration\n",
    "    combined_results = pd.DataFrame()\n",
    "\n",
    "    # List to store dataframes to be concatenated later\n",
    "    data_frames = []\n",
    "\n",
    "    # Iterate over each result file\n",
    "    for file in result_files:\n",
    "        # Load the results for each experiment\n",
    "        if type_city in file:\n",
    "            results = pd.read_csv(file)\n",
    "            \n",
    "            # Append the results to the list of dataframes\n",
    "            data_frames.append(results)\n",
    "\n",
    "    # Concatenate all dataframes in the list\n",
    "    if data_frames:\n",
    "        combined_results = pd.concat(data_frames)\n",
    "\n",
    "    # Calculate the average AUC for each model\n",
    "    average_auc_per_model = combined_results.groupby('Model')['AUC'].mean()\n",
    "    \n",
    "    # Sort the models by average AUC in descending order\n",
    "    sorted_models = average_auc_per_model.sort_values(ascending=False)\n",
    "    \n",
    "    # Get the top 5 models\n",
    "    top_5_models = sorted_models.head(5).index.tolist()\n",
    "\n",
    "    # Filter the results to include only the rows corresponding to the top 5 models\n",
    "    filtered_results = combined_results[combined_results['Model'].isin(top_5_models)]\n",
    "\n",
    "    # Calculate the average AUC for each model\n",
    "    average_auc_by_model = filtered_results.groupby('Model')['AUC'].mean()\n",
    "    \n",
    "    # Create a row with type_city and average AUC values for each model\n",
    "    row = {'type_city': type_city}\n",
    "    row.update(average_auc_by_model.to_dict())\n",
    "    \n",
    "    # Append the row to the summary_results DataFrame\n",
    "    summary_results = pd.concat([summary_results, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "# Display the summary_results DataFrame\n",
    "print(summary_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_city</th>\n",
       "      <th>BernoulliNB</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>NearestCentroid</th>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <th>LinearSVC</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <th>SGDClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>big</td>\n",
       "      <td>0.764115</td>\n",
       "      <td>0.669090</td>\n",
       "      <td>0.660482</td>\n",
       "      <td>0.715620</td>\n",
       "      <td>0.657869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small</td>\n",
       "      <td>0.810223</td>\n",
       "      <td>0.654498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.685329</td>\n",
       "      <td>0.666221</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all</td>\n",
       "      <td>0.799321</td>\n",
       "      <td>0.673888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.834474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675165</td>\n",
       "      <td>0.676748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type_city  BernoulliNB  ComplementNB  GaussianNB  NearestCentroid   \n",
       "0       big     0.764115      0.669090    0.660482         0.715620  \\\n",
       "1     small     0.810223      0.654498         NaN         0.853362   \n",
       "2       all     0.799321      0.673888         NaN         0.834474   \n",
       "\n",
       "   QuadraticDiscriminantAnalysis  LinearSVC  MultinomialNB  SGDClassifier  \n",
       "0                       0.657869        NaN            NaN            NaN  \n",
       "1                            NaN   0.685329       0.666221            NaN  \n",
       "2                            NaN        NaN       0.675165       0.676748  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  type_city       AUC  Accuracy  Precision    Recall\n",
      "0       big  0.689336  0.819802   0.662562  0.689336\n",
      "1     small  0.722180  0.887707   0.654480  0.722180\n",
      "2       all  0.731919  0.860643   0.656496  0.731919\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get a list of all result files from different experiments\n",
    "result_files = glob.glob(\"../results/*.csv\")\n",
    "\n",
    "# Create an empty DataFrame to store the summary\n",
    "summary_results = pd.DataFrame(columns=['type_city', 'AUC', 'Accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "# Iterate over each type of city\n",
    "for type_city in ['big', 'small', 'all']:\n",
    "    # List to store the DataFrames for each file of the current type_city\n",
    "    data_frames = []\n",
    "\n",
    "    # Iterate over each result file\n",
    "    for file in result_files:\n",
    "        # Load the results for each experiment\n",
    "        if type_city in file:\n",
    "            results = pd.read_csv(file)\n",
    "            # Add to the list of dataframes to be concatenated\n",
    "            data_frames.append(results)\n",
    "\n",
    "    # Concatenate all dataframes into one DataFrame if data exists\n",
    "    if data_frames:\n",
    "        combined_results = pd.concat(data_frames)\n",
    "\n",
    "        # Filter the results to include only the rows corresponding to the top 5 models\n",
    "        filtered_results = combined_results[combined_results['Model'].isin(top_5_models)]\n",
    "\n",
    "        # Calculate the average values for each metric (AUC, Accuracy, Precision, Recall)\n",
    "        average_metrics_per_model = filtered_results.groupby('Model')[['AUC', 'Accuracy', 'Precision', 'Recall']].mean()\n",
    "\n",
    "        # Calculate the mean of the average metrics across the top 5 models\n",
    "        average_values = average_metrics_per_model.mean()\n",
    "\n",
    "        # Create a row with type_city and the average metric values\n",
    "        row = {'type_city': type_city}\n",
    "        for metric in ['AUC', 'Accuracy', 'Precision', 'Recall']:\n",
    "            row[metric] = average_values[metric]\n",
    "\n",
    "        # Append the row to the summary_results DataFrame\n",
    "        summary_results = pd.concat([summary_results, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "# Display the summary_results DataFrame\n",
    "print(summary_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NearestCentroid',\n",
       " 'BernoulliNB',\n",
       " 'SGDClassifier',\n",
       " 'MultinomialNB',\n",
       " 'ComplementNB']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_results.to_csv(\"../results/summary_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
